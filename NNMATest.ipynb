{
 "metadata": {
  "name": "",
  "signature": "sha256:073dae46f26a70bdade786c7e497e13cf1138a111414abe3e5f6b62411102985"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      " <div align=\"center\"> A toy example on machine learning: <br>\n",
      "\"Learning\" a colour image using non-negative matrix approximation </div>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I am going to use an accessible example to try to explain my PhD research on x-ray spectromicroscopy imaging and classifying absorption spectra using non-negative matrix approximation (NNMA).  (Don't worry if it doesn't resonate with you immediately &mdash; keep reading!  The purpose of this page is to show a tangible example!)\n",
      "\n",
      "I'll start with some introduction about what NNMA does, relate it experimental x-ray samples, introduce an accessible analogy, show some Python code that performs the NNMA itself, present the results, and finally add some concluding comments.\n",
      "\n",
      "Non-negative matrix approximation (NNMA, or also NMF, for non-negative matrix factorization) has been used as a learning algorithm in facial recognition.  The idea is to \"factorize\" a database of faces into their component features (parts of the eyes, nose, mouth, etc.), with each feature having some weighting.  This process simplifies a jumble of faces into a simpler set (of component features).  Then, given a new face, could we figure out whether this face belongs to the database (perhaps posed under different lighting conditions, or tilted at a different angle), or is it an entirely new face?  If we could add up the features we've just learned in some weighted combination to match this face, then we have successfully recognized the new face as one already belonging to the database.  If not, then it is likely not a face in the original database.\n",
      "\n",
      "Now, instead of a database of faces, we have a stack of 2D x-ray absorption images of some sample (say, a biological cell).  Each of the images in the stack is of the same sample, only differing in x-ray absorption energy.  If you choose a fixed pixel on the image, and traverse down the stack, you can see how the absorption of that pixel changes as a function of energy &mdash; this is the absorption spectrum at that pixel.  As an analogy to the face database described above: each spectrum is like a series of faces of the same person under different conditions, and each pixel is like the face of a different person.  So we have a set of many, many spectra (as many spectra as there are pixels in the image, could be >10<sup>6</sup>), and we would like to decompose them into a smaller, simpler set which could still be added up in some weighted combination to reconstruct the spectrum of any pixel.  In a nutshell: we can use NNMA to unmix or reduce the large set of mixed spectra into the simplest set possible which would still contain the information needed to reconstruct any of the original spectra.  This simpler set provides a clearer picture for understanding the chemical components that make up the sample.\n",
      "\n",
      "OK, enough with the words &mdash; onto the promised tangible example!  (Note: as with any simplified analogy, the correspondence is not exact and some details are not accounted for; but simplifications often offer insights that can help clarify a more complex problem.)\n",
      "\n",
      "Suppose you have an RGB colour image (of anything colourful; say, peppers): <br><img src=\"figures/peppers.jpg\" width=\"50%\">\n",
      "\n",
      "Each pixel contains some colour, but even two red pixels may not be the exact same shade of red.  So here we have 503&times;302 pixels &mdash; potentially 151,906 different shades of different colours.  Can we reduce this set into a smaller set that could still be used to reconstruct the colour of any given pixel?  For an RGB image, the answer is already given: yes!  Each pixel is an (R, G, B) tuple (where each of the R, G, and B can take on any value from 0 to 255 inclusive) and so can be decomposed into its R (red), G (green), and B (blue) components!  The values in the tuples are just the weightings of the respective components in the pixel.<br>\n",
      "E.g., (255, 128, 0) represents fully saturated red + half-saturated green + no blue = an orangey colour.  \n",
      "\n",
      "So instead of describing the image using 151,906 different colours, each pixel is now specified instead as some weighted combination of 3 colours.  Thus we have reduced it a big, chaotic set of colours to a simpler set of just 3!  \n",
      "\n",
      "The above may sound obvious (or maybe not), but let's relate this back to our x-ray spectromicroscopy application: at each pixel in the image, the absorption spectrum is a result of the absorption characteristics of a mixture of materials.  We don't necessarily know what the materials are, nor their ratios.  Since the amount of each material may differ in each pixel, we have as many different absorption spectra as there are number of pixels (as mentioned above, possibly >10<sup>6</sup>).  We would like to reduce this vast set of spectra to a smaller set, which can be used (in some weighted combination) to describe the absorption of any pixel.  This smaller set, like the {R, G, B} set of colours, can shed light on the understanding of the material composition of a sample.  (Small note: instead of a set like {R, G, B}, in this case we're looking for a set of spectra; each spectrum is an array of numbers that is a function of energy, not a scalar value like R, or G, or B.  But this is just some detail that's not too important for the purpose of this illustration.)\n",
      "\n",
      "Let's run an NNMA test on an RGB image to decompose it into its components and respective weightings, then use them to reconstruct the image and compare it with the original."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will write an <tt>NNMATest</tt> class, which contains the iterative update functions and cost function calculations used in NNMA.  It also plots the results.  If you are running an active version of this page, you can change the parameters in the <tt>main</tt> function at the end to see how results vary (e.g., you can insert your favourite RGB image, or change the number of components to look for, etc. &mdash; the parameters will be explained below)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import Image\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.cm as cm\n",
      "from IPython import display\n",
      "import time"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class NNMATest():\n",
      "\n",
      "    # Assume an RGB image file is given\n",
      "    def __init__(self, fileName, nComponents=3, sparseParam=0.5, maxIters=10, plotPixComp=False):\n",
      "        self.imgOrig = Image.open(fileName)\n",
      "        imArray = np.array(self.imgOrig)\n",
      "        imArray = imArray / 255.  # scale all RGB values wrt 1\n",
      "        self.nRows = imArray.shape[0]\n",
      "        self.nCols = imArray.shape[1]\n",
      "        self.nPixels = self.nRows * self.nCols\n",
      "        data = np.zeros((3, self.nPixels))\n",
      "        for i in range(3):\n",
      "            data[i, :] = imArray[:, :, i].flatten()\n",
      "        self.data = data  # data matrix we want to reconstruct\n",
      "        self.nComponents = nComponents  # no. of \"hidden\" components to extract\n",
      "        self.sparseParam = sparseParam  # sparseness parameter\n",
      "        self.maxIters = maxIters  # max no. of iterations to run\n",
      "        self.frequencies = np.array([0., 1., 2.])  # our independent variable: in this case, the RGB colours\n",
      "        self.nFrequencies = len(self.frequencies)\n",
      "        self.plotPixComp = plotPixComp  # toggle whether to plot component composition of each pixel\n",
      "\n",
      "        \n",
      "    # Initialize the colour and weighting matrices\n",
      "    def initMatrices(self):\n",
      "        cInit = np.random.rand(self.nFrequencies, self.nComponents)\n",
      "        wInit = np.random.rand(self.nComponents, self.nPixels)\n",
      "        return cInit, wInit\n",
      "    \n",
      "    # Update the weighting matrix\n",
      "    def wUpdate(self, c, w):\n",
      "        wUpdateFactor = np.dot(c.T, self.data) / (np.dot(c.T, np.dot(c, w)) \n",
      "                                                  + self.sparseParam + 1e-9 )\n",
      "        wUpdated = w * wUpdateFactor\n",
      "        negInd = np.where(wUpdated < 0.)\n",
      "        if negInd:\n",
      "            wUpdated[negInd] = 1e-5\n",
      "        return wUpdated\n",
      "\n",
      "    # Update the colour matrix\n",
      "    def cUpdate(self, c, wUpdated):\n",
      "        cUpdateFactor = np.dot(self.data, wUpdated.T) / (np.dot(c, np.dot(wUpdated, wUpdated.T)) \n",
      "                                                    + 1e-9 )\n",
      "        cUpdated = c * cUpdateFactor\n",
      "        negInd = np.where(cUpdated < 0.)\n",
      "        if negInd:\n",
      "            cUpdated[negInd] = 1e-5\n",
      "        # Normalize each column of c\n",
      "        for k in range(self.nComponents):\n",
      "            cUpdated[:, k] = cUpdated[:, k] / np.sum(cUpdated[:, k]) * 255.\n",
      "            \n",
      "        return cUpdated\n",
      "    \n",
      "    # Calculate the cost function to be minimized\n",
      "    def calcCost(self, c, w, count):\n",
      "        dataRecon = np.dot(c, w)\n",
      "        costBasic = 0.5 * (np.linalg.norm(self.data - dataRecon))**2\n",
      "        costSparse = np.sum(np.sum(np.abs(w)))\n",
      "        costTotal = costBasic + self.sparseParam * costSparse\n",
      "        self.costArray[count, 0] = costTotal\n",
      "        if (count > 0):\n",
      "            deltaCost = self.costArray[count, 0] - self.costArray[count-1, 0]\n",
      "        elif (count == 0):\n",
      "            deltaCost = 1e-13\n",
      "        self.costArray[count, 1] = deltaCost\n",
      "        return costTotal, deltaCost\n",
      "    \n",
      "    # Plot results\n",
      "    def plotResults(self):\n",
      "        # Plot original image\n",
      "        figRecon = plt.figure(0, figsize=(15, 15))\n",
      "        plt.subplot(1, 3, 1)\n",
      "        plt.title(\"Original image\")\n",
      "        plt.imshow(self.imgOrig, origin=\"lower\")\n",
      "        \n",
      "        # Plot reconstructed image\n",
      "        imgReconTemp = self.dataRecon.reshape((self.nFrequencies, self.nRows, self.nCols))\n",
      "        imgReconTemp = imgReconTemp / np.amax(imgReconTemp)\n",
      "        imgRecon = np.zeros((self.nRows, self.nCols, self.nFrequencies))\n",
      "        for k in range(self.nFrequencies):\n",
      "            imgRecon[:, :, k] = imgReconTemp[k, :, :]\n",
      "        imgRecon = Image.fromarray(np.uint8(imgRecon*255.), \"RGB\")\n",
      "        plt.subplot(1, 3, 2)\n",
      "        plt.title(\"Reconstructed image\")\n",
      "        plt.imshow(imgRecon, origin=\"lower\")\n",
      "        \n",
      "        # Plot difference between original and reconstructed images\n",
      "        dataDiffTemp = np.abs(self.data - self.dataRecon).reshape(\n",
      "            (self.nFrequencies, self.nRows, self.nCols))\n",
      "        dataDiffTemp = dataDiffTemp / np.amax(dataDiffTemp)\n",
      "        dataDiff = np.zeros((self.nRows, self.nCols, self.nFrequencies))\n",
      "        for k in range(self.nFrequencies):\n",
      "            dataDiff[:, :, k] = dataDiffTemp[k, :, :]\n",
      "        dataDiff = Image.fromarray(np.uint8(dataDiff*255,), \"RGB\")\n",
      "        plt.subplot(1, 3, 3)\n",
      "        plt.title(\"Difference image\")\n",
      "        plt.imshow(dataDiff, origin=\"lower\")\n",
      "\n",
      "        # Plot each component's \"spectrum\" and image\n",
      "        plt.figure(1, figsize=(15, 15))\n",
      "        self.wRecon = self.wRecon.reshape((self.nComponents, self.nRows, self.nCols))\n",
      "        colours = ['r', 'g', 'b', 'm', 'c', 'y', 'k']\n",
      "        for k in range(self.nComponents):\n",
      "            if k < len(colours): lineColour = colours[k]\n",
      "            else: lineColour = 'k'\n",
      "            plt.subplot(self.nComponents, 2, k*2+1)\n",
      "            plt.title(\"Component %s spectrum\" %(k+1))\n",
      "            plt.plot(self.frequencies, self.cRecon[:, k], linewidth=3., color=lineColour)\n",
      "            plt.subplot(self.nComponents, 2, (k+1)*2)\n",
      "            plt.title(\"Component %s image\" %(k+1))\n",
      "            plt.imshow(self.wRecon[k, :, :], cmap=cm.gray)\n",
      "        \n",
      "        display.display(plt.gcf())\n",
      "        plt.close()\n",
      "    \n",
      "    # Visualize how each pixel's component content changes during iterations\n",
      "    def plotWPixels(self, ind, count):\n",
      "        wReconNorm = self.wRecon / np.amax(self.wRecon)\n",
      "        wRecon_0 = wReconNorm[0, ind]\n",
      "        wRecon_1 = wReconNorm[1, ind]\n",
      "        wRecon_2 = wReconNorm[2, ind]\n",
      "        plt.figure(3, figsize=(15, 8))\n",
      "        axMin = -0.1\n",
      "        axMax = 1.\n",
      "        plt.subplot(1, 3, 1)\n",
      "        plt.cla()\n",
      "        plt.scatter(wRecon_0, wRecon_1, marker='o', color='brown', edgecolor=\"none\")\n",
      "        plt.xlabel(\"Component 1\")\n",
      "        plt.ylabel(\"Component 2\")\n",
      "        plt.xlim([axMin, axMax])\n",
      "        plt.ylim([axMin, axMax])\n",
      "        plt.subplot(1, 3, 2)\n",
      "        plt.cla()\n",
      "        plt.scatter(wRecon_0, wRecon_2, marker='o', color='m', edgecolor=\"none\")\n",
      "        plt.title(\"Iteration progress: {0}/{1}\".format(count, self.maxIters))\n",
      "        plt.xlabel(\"Component 1\")\n",
      "        plt.ylabel(\"Component 3\")\n",
      "        plt.xlim([axMin, axMax])\n",
      "        plt.ylim([axMin, axMax])\n",
      "        plt.subplot(1, 3, 3)\n",
      "        plt.cla()\n",
      "        plt.scatter(wRecon_1, wRecon_2, marker='o', color='c', edgecolor=\"none\")\n",
      "        plt.xlabel(\"Component 2\")\n",
      "        plt.ylabel(\"Component 3\")\n",
      "        plt.xlim([axMin, axMax])\n",
      "        plt.ylim([axMin, axMax])\n",
      "        display.clear_output(wait=True)\n",
      "        display.display(plt.gcf())\n",
      "        time.sleep(0.2)        \n",
      "        plt.close()\n",
      "    \n",
      "    # Begin NNMA calculations\n",
      "    def calcNNMA(self):\n",
      "        print(\"Starting NNMA:\")\n",
      "        cInit, wInit = self.initMatrices()\n",
      "        self.costArray = np.zeros((self.maxIters+1, 2))\n",
      "        self.cRecon = cInit\n",
      "        self.wRecon = wInit\n",
      "        count = 0\n",
      "        cost, deltaCost = self.calcCost(cInit, wInit, count)\n",
      "        # If plotPixComp==True, pick 100 random pixels to plot their component distribution\n",
      "        ind = np.random.random_integers(0, self.nPixels, 1000)\n",
      "        if self.plotPixComp == True: self.plotWPixels(ind, count)\n",
      "        while (count < self.maxIters) and ((deltaCost < -1e-6) or (deltaCost > 0.)):\n",
      "            count = count + 1\n",
      "            wUpdated = self.wUpdate(self.cRecon, self.wRecon)\n",
      "            cUpdated = self.cUpdate(self.cRecon, wUpdated)\n",
      "            cost, deltaCost = self.calcCost(cUpdated, wUpdated, count)\n",
      "            self.cRecon = cUpdated\n",
      "            self.wRecon = wUpdated\n",
      "            self.dataRecon = np.dot(self.cRecon, self.wRecon)\n",
      "            if (count%10 == 0):\n",
      "                if self.plotPixComp == True:\n",
      "                    self.plotWPixels(ind, count)\n",
      "                else:\n",
      "                    print \"Iteration progress: {0}/{1}\".format(count, self.maxIters)\n",
      "                    display.clear_output(wait=True)\n",
      "                            \n",
      "            \n",
      "        self.plotResults()\n",
      "        "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you're running an active version of this page, you can run the <tt>main</tt> function in the cell below to display results.  The arguments and keyword arguments can be customized to see how the results vary.\n",
      "\n",
      "<ul>\n",
      "<li> <tt>fileName</tt>: insert the file name of your favourite RGB image; </li>\n",
      "<li> <tt>nComponents</tt>: the (unknown, estimated) number of components to look for; </li>\n",
      "<li> <tt>sparseParam</tt>: the sparseness parameter describing the dataset; </li>\n",
      "<li> <tt>maxIters</tt>: the max number of iterations to run; </li>\n",
      "<li> <tt>plotPixComp</tt>: whether to plot distribution of component content of pixels during iterations.  The more sparse you choose <tt>sparseParam</tt> to be, the more you will see the pixels migrate towards one of the two axes (which means that you're trying to force each pixel to belong purely to one component, rather than some mixture).  (Note: it's nice to watch the pixels move, but the plot renderings slow down computation time). </li>\n",
      "</ul>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if __name__ == \"__main__\":\n",
      "    fileName = \"figures/peppers.jpg\"\n",
      "    test = NNMATest(fileName, nComponents=3, sparseParam=0.3, maxIters=1000, plotPixComp=False)\n",
      "    test.calcNNMA()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you're not running an active version of this page, then here I'll show the results of running the above code.  First, the individual components (representing R, G, B) on the left, and their corresponding weighting maps on the right: <br><img src=\"figures/components.png\" width=\"50%\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Wherever the weighting map is brighter, those pixels contain more of that corresponding component.  For example, in the component 3 thickness map, the red peppers show up as the brightest &mdash; so the component 3 represents R in this case (despite the fact that it's drawn in blue).  Similarly, component 1 represents G, and component 2 represents B.  The white-coloured garlic shows up quite strongly in all of the components because white contains all three components. "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now this is what happens when we combine (matrix multiply) the discovered components with their weighting maps: \n",
      "<br><img src=\"figures/reconstruction.png\"><br>\n",
      "Not bad!  We can reduce the error even further by running more iterations."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Some comments:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We mentioned before that there are some limits to the comparison between running NNMA on RGB images and running it on x-ray spectromicroscopy images.  One such limit is this:\n",
      "\n",
      "We've interpreted the 3 components that we extracted using NNMA as the 3 basic RGB colours that make up each pixel.  This is cheating a bit, since we <em>knew beforehand</em> that the format of the image is RGB and that each pixel is composed of an RGB tuple, and so we knew to decompose the image into 3 components.\n",
      "\n",
      "In x-ray spectromicroscopy, we <em>don't</em> know beforehand how many components to look for, since we don't usually know what the sample is composed of exactly.  We may have some prior knowledge about the sample &mdash; say, it contains different compounds of copper &mdash; but we don't know exactly which ones, nor how many different kinds, so there is some guesswork involved (fortunately, not pure guesswork as there are other methods we could run on the data before NNMA, such as principal component analysis and cluster analysis, to get an idea beforehand about the number and variation of components in the sample).\n",
      "\n",
      "This is like trying to run NNMA on an RGB image not knowing what objects are in it, and seeing if we could find components that represent peppers, garlic, the backdrop, etc.  But the image itself does not contain this information (a pixel representing a purple background would contain exactly the same RGB tuple as a pixel representing a pepper with the same purple colour, for example) &mdash; so we cannot run NNMA on an RGB image and expect to discover this type of information  (though there are other image classification techniques that could be used for this).  X-ray absorption spectra, however, do contain information about the chemical content of the material at each pixel &mdash; and that's why it's interesting to apply NNMA to x-ray spectromicroscopy images to study the composition of materials!\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So I'll end with one of the samples that I've used NNMA on: a human sperm cell (x-ray spectromicroscopy experiment undertaken by H. Fleckenstein) &mdash; component absorption spectra on the left, component weighting maps on the right (components correspond to: background, flagellum, mitochondria sheath and posterior ring, acrosomal cap, and nucleus): <br>\n",
      "<img src=\"figures/spermNNMA.png\" width=\"50%\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There are a few things I have not discussed in detail above, such as how to choose the number of components to start with, smoothness and sparseness regularizations, comparison with cluster analysis spectra as a basis set, etc.  If you are interested, you can read more about it in this paper: <br>\n",
      "Mak, R., Lerotic, M., Fleckenstein, H., Vogt, S., Wild, S. M., Leyffer, S., Sheynkin, Y.,\n",
      "and Jacobsen, C., \"Non-negative matrix analysis for effective feature extraction in x-ray\n",
      "spectromicroscopy\", <em>Faraday Discuss.</em> <strong>171</strong>, doi:10.1039/c4fd00023d (2014)"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}